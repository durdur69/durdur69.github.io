<html>
<head>
    <title>You (Probably) Aren't Conscious Right Now</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content='First Principles.'>
    <meta name='keywords' content=''>
    <meta name='author' content='Adam Green'>

    <link href='/css/blog.css' rel='stylesheet'/>
    <link href='/css/trac.css' rel='stylesheet'/>
    <link href='/css/markdown.css' rel='stylesheet'/>
    <script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>

<script src='//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML' type='text/javascript'></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
</head>
<body>
<div class='content'>
    <div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Home</a></li>
        <li><a href='/about'>About</a></li>
        <li><a href='/feed.xml'>RSS</a></li>
    </ul>
</div>
    <div class='front-matter'>
        <div class='wrap'>
            <h1>You (Probably) Aren't Conscious Right Now</h1>
            <h4>Preliminary thoughts on consciousness and attention.</h4>
            <div class='bylines'>
                <div class='byline'>
                    <h3>Published</h3>
                    <p>14 April 2017</p>
                </div>
            </div>
            <div class='clear'></div>
        </div>
    </div>
    <div>
        <div id="table-of-contents">
            
            
        </div>
        <div class="wrap article">
          <p><em>My first foray into philosophy of mind, c. 2017; a followup essay, which extends these concepts, can be found <a href="https://adamlgreen.com/searching-for-self/">here.</a></em></p>

<p>As I write this paper it seems as if I am undergoing a set of sensory experiences. I pick up my mug and <em>feel</em> its warmth in my hand; I <em>taste</em> the coffee; I <em>hear</em> the pitter-patter of the rain outside my window. These experiences all seem to have distinctly mental properties such as phenomenality—there is something it is <em>like</em> for me to be undergoing these experiences—subjectivity—<em>I</em> am the one undergoing these experiences—and privacy—I have <em>special first-person knowledge</em> of these experiences that others don’t. While these properties may seem metaphysically special, I will argue that they, and all other mental properties, are not special. The specialness of these properties is an illusion, one which is so convincing and pervasive that it is nearly impossible to see through, but ultimately these properties are nothing more than complex physical properties.</p>

<p>I’ll provide a summary of my view of the natural world: I am a physicalist. I don’t believe in the existence of immaterial souls, ghosts or ghouls, and thus am firmly opposed to substance dualism. I believe that we can learn about the natural world by testing falsifiable claims and providing evidence to support these claims. That said, we can never truly prove a claim; the best we will ever get is a plausible explanation, not certainty. Therefore, scientific claims are provisional and subject to change. In my argument, I rely heavily on evolutionary theory (i.e. the principles of evolution via natural selection), which I believe is an example of such a scientific theory that makes falsifiable and testable claims.</p>

<p>Here’s how the paper is structured. In Part 1, I’ll define important terms and discuss Levine’s “explanatory gap”. In Part 2, I’ll propose four possible evolutionary explanations of the mental. In Part 3, I’ll discuss the adaptive value of theory of mind and explain the Attention Schema Theory, a potential explanation of how the illusion of subjectivity arises from purely physical processes. Finally, I will address objections to my argument.</p>

<p><em><u>The Explanatory Gap</u></em></p>

<p>I will use the term <em>the mental</em> to refer to the class of properties which folk psychology classifies as metaphysically special as compared to purely physical properties: phenomenality, subjectivity, intentionality, etc. I will interchangeably use the terms <em>consciousness</em> and <em>subjectivity</em> to refer to state consciousness—that is, mental states that possess these mental properties (Van Gulick, <em>Consciousness</em>). Under my definition, consciousness encompasses both sensations and propositional attitudes, though my argument is focused on sensations. The definitions I’ve provided are quite nebulous. By the end of this paper I hope to show you that this is for good reason: while useful abstractions, talk of the mental and consciousness is ultimately as absurd as talk of spirits or ghosts.</p>

<p>While we can reduce physical phenomena (e.g. a baseball player throwing a baseball) down to physics and chemistry, most people agree that there is special class of things which possess properties that can’t be explained via the same physics and chemistry: the mental. No matter how much we know about the physics of echolocation or the flavor profile of insects, it seems that we can never truly understand “what it is like” to be a bat, for example (Nagel, 1974, 437). There is a certain first-person subjectivity, a distinct phenomenal character of the bat’s experience that we can never understand in the same way it does. In folk psychology, we call this property <em>phenomenality</em>. Even as our neuroscience and psychology advances, materialism seems to be left with this intractable epistemological problem of explaining these mental properties in purely physical terms. Levine calls this “the explanatory gap” (Levine, 1983, 360).</p>

<p>While the explanatory gap seems obviously insurmountable, I will argue that it is not. It only seems insurmountable because we are so entrenched in folk psychology and talk of the mental that we can’t look at the mental in a sober manner. To understand the mental, we ought to question what causes its existence to seem so obvious to us.</p>

<p><em><u>Four Explanations of the Mental</u></em></p>

<p>Mental properties didn’t just pop up out of nowhere. Like any physical property, such as the ability to breath air, mental properties need to have arisen somewhere in our evolutionary development to be consistent with a naturalistic explanation of the world. This could have occurred in four possible ways:</p>

<ol>
  <li>A supernatural being like a god gave us these mental properties, and thus they are still metaphysically special.</li>
  <li>Mental properties are an emergent property of complex information-processing which arose somewhere in our evolutionary development, and thus the mental is still special.</li>
  <li>Our ancestors, all the way back to single-cell organisms, had the precursors of mental properties; therefore, mental properties are graded yet still special.</li>
  <li>Metaphysically special mental properties never actually arose in our evolutionary development. They are an illusion, and thus we don’t have them.</li>
</ol>

<p>We can discard the first explanation, as it isn’t consistent with naturalism; the third explanation, the panprotopsychist explanation, seems just as absurd so we can discard it too. [<em>Note: due to word count, I was unable to provide a fully fleshed out objection to panprotopsychism; ideally I would have explained why I think it is absurd, rather than dismiss the idea with a single sentence]</em>. While the second explanation seems sensible, I will argue that if we probe deeper we will see it is has some holes. Firstly, at what point in our evolutionary history did these mental properties arise? We face an infinite regress problem here. No matter where you point in our evolutionary history, from the development of nervous systems or the genus <em>Homo</em>, we still face an (evolutionary) explanatory gap. As this might lead you to believe, perhaps mental properties never arose in our evolutionary history and explanation four is correct.</p>

<p><em><u>Illusions, Theory of Mind, and the Attention Schema Theory</u></em></p>

<p>While explanation four logically makes sense, it runs counter to our intuitions about the mental. Surely you are conscious as you read this: how couldn’t you be? As I hope to show, this consciousness—a mental property which we attribute to our self and others—is an illusion, a trick the human brain plays on itself (Frankish, 2016).</p>

<p>First, let’s address theory of mind—our attribution of mental properties and minds to other people—which is the core of folk psychology. Do we know that other people have minds and mental properties? No, we do not have proof of this. For all we know, other people could act as if they have minds and mental properties but just be “philosophical zombies” (Kirk, <em>Zombies</em>). Nevertheless, we still attribute the mental to others because of induction: if I have a mind and am a human being, it seems most parsimonious for other human beings to have minds and not be zombies. However, we ought to doubt the antecedent, for as I will show, the attribution of a mind to our self relies on the exact same sort of induction we use when we attribute minds to others; that is, we don’t have any sort of privileged first-person knowledge of our own mind that would allow us to use induction to infer that others have similar minds.</p>

<p>To show that minds and mental properties are an illusion, I will first explain the adaptive value of believing in them. Consider trying to develop an atom-for-atom representation of another human being whom you are competing with. For a human brain, this is computationally impossible. However, when you abstract and use heuristics such as the concept of a “mind” or a “person” you can predict the behavior of other humans. Thus, theory of mind is simply a heuristic which facilitates cooperation, increasing the evolutionary fitness—that is, surviving and producing fertile offspring—of the individual and the species. What differentiates humans from most other species is our complex social behavior, which is predicated on theory of mind. Thus, theory of mind is a useful and evolutionarily adaptive heuristic, but that doesn’t necessarily mean that it’s a realistic representation of the world.</p>

<p>Looking back at our evolutionary history, we can see the progression from simple neuronal competition to full-fledged theory of mind. It all began roughly 700 million years ago, when our animal lineage split off from the lineage of animals without nervous systems, such as the sponge (Graziano &amp; Webb, 2017, 547). We then see the development of the precursor of attention, “selective signal enhancement,” in which neurons compete for their signal to beat out the signal of other neurons; those neurons that win have their signals amplified and those that lose have their signals diminished (Graziano, 2014, 1300). This enhancement is bottom-up. Conversely, the top-down control of which signals are enhanced later developed, and we call this top-down control <em>attention</em> (Graziano, 2017, 548). If you’re asked to find Waldo among a crowd of people, you are exerting attention, turning up the gain on neurons which are tuned to certain red and white visual stimuli and turning down the gain on neurons tuned to other visual stimuli.</p>

<p>Per the Attention Schema Theory proposed by Webb and Graziano, the metaphysically special mental property we call subjectivity “is the brain’s internal model of the process of attention” (Webb &amp; Graziano, 2015, 1). That is, awareness is a <em>mental schema</em>, a construct which facilitates our ability to control attention and leads to the illusion of subjectivity. Attention is the top-down control of how our neurons process incoming stimuli, and awareness is our model of this process (Webb &amp; Graziano, 2015, 2).</p>

<p>For example, when we drink coffee, our taste buds are stimulated, leading to a certain pattern of brain activity. Perhaps we like coffee, so certain neurotransmitters are released in the brain and we emit an audible “yum”. Here there is a causal relationship between the physical process of drinking the coffee and our physiological reactions to it. Only when we apply the schema of awareness and the schema of the self to these physical processes do we begin to believe that we are undergoing a sensory experience composed of metaphysically special properties.</p>

<p>However, this belief need not mean that we are actually undergoing a phenomenal experience. As stated before, the apparent phenomenality of our experience comes from attributing this mental schema called <em>awareness</em> to ourselves (Webb &amp; Graziano, 2015, 6). This is the same schema we attribute to others as part of theory of mind. Thus, we don’t have any privileged first-person access to our own mental life; this first-person perspective is simply a consequence of our mental schema.</p>

<p>Evidence for the Attention Schema Theory comes from the psychology of illusions. In one experiment, subjects’ view of their left hand and arm is occluded by a screen, and they are told to focus on a rubber arm and hand placed in front of them. The experimenters simultaneously brush the real arm and the rubber arm for ten minutes. Subjects report that “they seemed to feel the touch not of the hidden brush but that of the viewed brush, as if the rubber hand had sensed the touch” (Botvinick &amp; Cohen, 1998, 756). In this example, the schema subjects had of their body—the “body schema”—was fooled (Webb &amp; Graziano, 2015, 5). We utilize mental schemata to make sense of the world, but as shown by this experiment, these schemata don’t always accurately represent the world as it is.</p>

<p>Meditation and introspection into our “first-person experience” also provide evidence for the illusoriness of subjectivity. If you simply close your eyes and sit there, without explicitly thinking about the fact that you are sitting, what is left? In the present moment, until you attend to the thought that you are sitting or that your nose itches, you don’t have the property of consciousness. As Susan Blackmore argues, “whenever we ask about consciousness, a temporary unit of a set of thoughts and perceptions is constructed and is linked to a representation of the self as a continuing observer” (Blackmore, 2016, 55). But up until that point, there is no metaphysically special property called consciousness to be found.</p>

<p>Attributing theory of mind to our self and others has adaptive value; we can track the development of theory of mind across broad swaths of evolutionary time; and we are beginning to explain how the illusion of consciousness arises. I believe that the most parsimonious explanation of all this evidence is that metaphysically special mental properties such as subjectivity and phenomenality don’t exist. Now that we realize the explanatory gap can be bridged, the challenge we face is what Dennett calls “the illusion problem—the problem of explaining how the illusion of phenomenality arises and why it is so powerful” (Dennett, 2016, 65).</p>

<p><em><u>Objections</u></em></p>

<p><em style="font-size: 1rem;">1. I’m conscious right now, so isn’t this evidence of me possessing mental properties?</em></p>

<p>I invite you to prove that you are conscious right now. If you probe your first-person experience, then you will see that you do not possess any metaphysically special property called consciousness. You may believe that you are conscious, and I cannot deny that you believe this. However, as stated before, this belief comes not from special first-person knowledge of your mental states, but instead comes from you utilizing a mental schema of attention called awareness, and attributing this awareness to yourself.</p>

<p>While convincing, this schema is as illusory as the existence of free will or the linearity of time. For example, until Einstein came along, we all thought that time was absolute and linear. But we now know that time is intimately tied with space and can dilate depending on your relationship to the earth or another gravitational mass (Markosian, <em>Time</em>).</p>

<p>I think it’s likely we will have similar revelations in neuroscience and psychology and will someday completely explain the illusion of the mental in purely physical terms. We will look back on mental properties in the same way we look back on properties such as <em>being phlogistonated</em> or <em>having an imbalance of humors</em>: as useful yet absurd, pre-theoretical constructs that we should have dispensed with a long time ago.</p>

<p><em style="font-size: 1rem;">2. If no organism has a mind, doesn’t this invalidate the existence of moral truth? Wouldn’t this give us license to be cruel to humans and non-human animals, increasing the net suffering in the world?</em></p>

<p>I would agree that there is no objective moral truth. Like theory of mind, morality is merely an evolutionary adaptation. Specifically, it is a way to deal with the free-rider problem, and we too can come up with convincing explanations of how it evolved and why it’s adaptive (Hardin, <em>The Free Rider Problem</em>). That said, my argument here isn’t normative. I don’t condone purposefully increasing the net suffering in the world. Humans seem to have reached a peak on the complexity landscape, and therefore perhaps the human project is special and something we ought to try to maintain.</p>

<p><em style="font-size: 1rem;">3. Doesn’t this mean that we could program machines to be conscious?</em></p>

<p>Yes, a machine could be conscious insofar as we are conscious; that is, we would call it conscious and say it has subjective experience, but it wouldn’t possess any metaphysically special mental properties. It would be performing the same sorts actions we do, just in silico.</p>

<p><u>References:</u></p>

<p>Blackmore, Susan. 2016. “Delusions of Consciousness.” <em>Journal of Consciousness Studies</em>, 23(11): 52–64.</p>

<p>Botvinick, Matthew, and Jonathan Cohen. 1998. “Rubber Hands ‘Feel’ Touch That Eyes See.” <em>Nature</em> 391(19): 756.</p>

<p>Dennett, Daniel C. 2016. “Illusionism as the Obvious Default Theory of Consciousness.” <em>Journal of Consciousness Studies</em>, 23(11): 65–72.</p>

<p>Frankish, Keith. 2016. “Illusionism as a Theory of Consciousness.” <em>Journal of Consciousness Studies</em>, 23(11): 11–39.</p>

<p>Graziano, Michael S. A. 2014. “Speculations on the Evolution of Awareness.” <em>Journal of Cognitive Neuroscience</em>, 26(6): 1300–1304.</p>

<p>Graziano, Michael S. A., and Taylor W. Webb. 2017. “From Sponge to Human: The Evolution of Consciousness.” In <em>Evolution of Nervous Systems (Volume 3)</em>, ed. Jon Kaas. Elsevier: Oxford.</p>

<p>Hardin, Russell. “The Free Rider Problem.” <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2013 Edition), ed. Edward N. Zalta. <a href="https://plato.stanford.edu/archives/spr2013/entries/free-rider/">https://plato.stanford.edu/archives/spr2013/entries/free-rider/</a>.</p>

<p>Kirk, Robert. “Zombies.” <em>The Stanford Encyclopedia of Philosophy</em> (Summer 2015 Edition), ed. Edward N. Zalta. <a href="https://plato.stanford.edu/archives/sum2015/entries/zombies/">https://plato.stanford.edu/archives/sum2015/entries/zombies/</a>.</p>

<p>Levine, Joseph. 1983. “Materialism and Qualia: The Explanatory Gap.” <em>Pacific Philosophical Quarterly</em>, 64: 354–361.</p>

<p>Markosian, Ned. “Time.” <em>The Stanford Encyclopedia of Philosophy</em> (Fall 2016 Edition), ed. Edward N. Zalta. <a href="https://plato.stanford.edu/archives/fall2016/entries/time/">https://plato.stanford.edu/archives/fall2016/entries/time/</a>.</p>

<p>Nagel, Thomas. 1974. “What Is It Like to Be a Bat?” <em>The Philosophical Review</em>, 83(4): 435–450.</p>

<p>Serino, Andrea, Alsmith, Adrian, Constantini, Marcello, Mandrigin, Alisa, Tajadura-Jimenez, Ana, and Christopher Lopez. 2013. “Bodily Ownership and Self-Location: Components of Bodily Self-Consciousness.” <em>Consciousness and Cognition</em>, 22: 1239–1252.</p>

<p>Webb, Taylor W., and Michael S. A. Graziano. 2015. “The Attention Schema Theory: A Mechanistic Account of Subjective Awareness.” <em>Frontiers in Psychology</em>, 5(500): 1–11.</p>

<p>Van Gulick, Robert. “Consciousness.” <em>The Stanford Encyclopedia of Philosophy</em> (Winter 2016 Edition), ed. Edward N. Zalta. <a href="https://plato.stanford.edu/archives/win2016/entries/consciousness/">https://plato.stanford.edu/archives/win2016/entries/consciousness/</a>.</p>

        </div>
      </div>
</div>
</body>
</html>
